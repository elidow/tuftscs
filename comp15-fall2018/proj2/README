/*********************************************************
 * Project 2: grep
 * Comp 15 Fall 2018 
 * 
 * Author: Eli Dow
 *
 *********************************************************/

Part 2:

TA Acknowledgements: Alice, Kevin, Hayden


FSTree.h		: interface of FSTree class  (used to explore file directories)
FSTree.o		: compiled version of FSTree.cpp
DirNode.h 		: interface of DirNode class (nodes used in FSTree)
DirNode.o 		: compiled version of DirNode.cpp
the_gerp		: compiled solution of this assignment (good for comparing
					 purposes)
sampleExecution : files to test your program (one input and three outputs)
test-dirs 		: simple template stack class used for DFS

FSTreeTraversal.cpp : driver of the program
					  accepts a directory and creates a Index object
					  as requests user for queries
StringProcessing.h: interface of StringProcessing class
StringProcessing.cpp : strips all leading and trailing 
					   non-alphanumeric characters from a string and returns it
Index.h			: interface of Index class(for hash table)
Index.cpp		: creates a hash table with a Dynamic Array of Linked Lists
				  the Linked Lists are of DataType objects
				  It only creates a new DataType object if it is a new word
LinkedList.h	: interface of the LinkedList class
LinkedList.cpp	: creates a LinkedList of a variable type defined in a template

^I got this from HW5

DataType.h		: interface of DataType class
DataType.cpp	: this class was created to represent each unique word
				  its attributes include a string(the word) and a vector
				  of strings that were the path, line #, line concatenated
README 			: this file


Compiled: make gerp
Run: ./gerp [directory] (./the_gerp [directory] to compare to)

Data Structures:
In this project, I implemented a hash table in my Index class. Hash tables
are really fast for inserting and searching, and it was really helpful when
looking at a massive number of files. I created the hash table with a 
dynamic array of Linked Lists. Each LinkedList was constructed of Datatype 
objects, which stored unique words and all paths to them. To determine which 
LinkedList(index of the DA) a word was placed, I hashed the word. That way,
every time I hash a certain word, it will always return the same index(hash).


Algorithms in FSTreeTraversal.cpp:
In FSTreeTraversal.cpp, I had a few helpful algorithms. First, to insert all
of the words from a directory's files, I recursively traversed through the 
directory with an DirNode object(main directory is the root). At a specific
file, it would call that file to the Index object. Second, to query, I would
traverse each input with a while loop calling get line. I would traverse through
the line and find words, also considering @i and @q commands. Once I'd have a 
word, I'd call a helper function that outputs all correct files for that word.
For case insensitive cases, I would call another helper function that would
find all permutations of a word(WE, We, wE, we). I did this knowing that the
possible perrmutations of a word are 2^(length of the word). I printed 
accordingly.

Algorithms in StringProcessing.cpp:
In StringProcessing.cpp, I create a while loop that reads in every input.
When the string is inputted, it keeps track of each word by marking a 
first character and last character marker. It accounts for multiple words
(checking if there is a space), and returns a string of every word found.

Algorithms in Index.cpp:
As mentioned in the Data Structures section, my hash table was created with
a Dynamic Array of Linked Lists(of DataType).  For my
insert function, I read in a file, break down each line into each word. If it
was a new word, I would create a new DataType object and insert in into the 
List. In the Data Structures section, I also talked about using the standard
library hash function to find the location of a word by hashing the word.
If it was an old word, I would just update that DataType object with a new path.
For my search function, I hashed a word to find its location in the the table.
When I found it, I would put all of its paths/lines into one string, making sure
I don't repeat any line. Finally, I also have an expand function. I determine
if the DA expands if the number of words(DataType objects) / buckets is greater
than .75. If it is, I create a new DA twice the size, and copy accordingly, 
while accounting for memory.


