{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eli Dow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW05 Code\n",
    "\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 05 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file, along with your COLLABORATORS.txt file and the two tree images (PDFs generated using `graphviz` within the code), to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/tufts/spring2021/comp135).\n",
    "\n",
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree\n",
    "import graphviz\n",
    "\n",
    "# for log function\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You should start by computing the two heuristic values for the toy data described in the assignment handout. You should then load the two versions of the abalone data, compute the two heuristic values on features (for the simplified data), and then build decision trees for each set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Compute both heuristics for toy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets represent the best toys for kids, and are based on the decision tree diagrams in the spec. The data-set consists of eight entries (children) and whether they would prefer an action-figure (1) or doll (0). Each entry has two features: is_male and likes_superheroes. is_male represents whether the child is male (1) or female (0), and likes_superheroes represents whether the child likes superheroes (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Toy Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_toydata = np.loadtxt('data_toys/x_data.csv', skiprows=1, delimiter=',')\n",
    "y_toydata = np.loadtxt('data_toys/y_data.csv', skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes_superheroes: 6/8 (0.75)\n",
      "is_male: 6/8 (0.75)\n"
     ]
    }
   ],
   "source": [
    "def compute_count_heuristic(x_data, y_data, outcomes, empty_h_values):\n",
    "    ''' Computes the counting heuristic values for each feature of x_data\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    x_data : 2D list of binary values\n",
    "        Each element in x_data represents a list of each data points features\n",
    "        Each feature is either a 1 or 0\n",
    "    y_data : 1D list of integers\n",
    "        Each element in y_data is an integer representing a particular classification\n",
    "    outcomes : integer value\n",
    "        Represents the number of possible classification outcomes\n",
    "    empty_h_values : list of tuples\n",
    "        Each tuple contains a feature name and its initial counting heuristic value (0)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    heuristic_values: list of tuples\n",
    "        Each tuple contains a feature name and its computed counting heuristic value (0)\n",
    "    '''\n",
    "    \n",
    "    # intialize heuristic values and total data\n",
    "    heuristic_values = empty_h_values\n",
    "    total_data = len(y_data)\n",
    "\n",
    "    # for each attribute\n",
    "    for feature in range(len(heuristic_values)):\n",
    "\n",
    "        # initialize positive features subset and data corresponding to them\n",
    "        true_feat = []\n",
    "        true_outcomes = [0] * outcomes\n",
    "        true_majority = 0\n",
    "        \n",
    "        # initialize false features subset and data corresponding to them\n",
    "        false_feat = []\n",
    "        false_outcomes = [0] * outcomes\n",
    "        false_majority = 0\n",
    "\n",
    "        # initialize variable for y_data based on subset majority\n",
    "        y_data_majority = []\n",
    "\n",
    "        # divide data set according to possible values of that attribute\n",
    "        # keep track of number of classifications for each subset\n",
    "        for dp in range(total_data):\n",
    "            if(x_data[dp][feature] == 1):\n",
    "                true_feat.append(dp)\n",
    "                true_outcomes[int(y_data[dp])] += 1\n",
    "            else:\n",
    "                false_feat.append(dp)\n",
    "                false_outcomes[int(y_data[dp])] += 1\n",
    "\n",
    "        # find majority in each subset\n",
    "        for i in range(1, len(true_outcomes)):\n",
    "            if (max(true_outcomes) == true_outcomes[i]):\n",
    "                true_majority = i\n",
    "            if (max(false_outcomes) == false_outcomes[i]):\n",
    "                false_majority = i\n",
    "\n",
    "        # assign all data points the majority value in its subset\n",
    "        for dp in range(total_data):\n",
    "            if len(true_feat) > 0 and dp == true_feat[0]:\n",
    "                y_data_majority.append(true_majority)\n",
    "                true_feat.pop(0)\n",
    "            elif len(false_feat) > 0 and dp == false_feat[0]:\n",
    "                y_data_majority.append(false_majority)\n",
    "                false_feat.pop(0)\n",
    "\n",
    "        # count total correct and store it\n",
    "        num_correct = 0\n",
    "        for dp in range(total_data):\n",
    "            if y_data_majority[dp] == y_data[dp]:\n",
    "                num_correct += 1\n",
    "        heuristic_values[feature] = tuple([heuristic_values[feature][0], num_correct])\n",
    "\n",
    "    # sort by heuristic value, descending order\n",
    "    heuristic_values.sort(key=lambda a: a[1])\n",
    "    heuristic_values.reverse()\n",
    "    \n",
    "    return heuristic_values\n",
    "\n",
    "\n",
    "# compute counting heuristic for toy data\n",
    "toy_h_values = compute_count_heuristic(x_toydata, y_toydata, 2, [('is_male', 0.0), ('likes_superheroes', 0.0)])\n",
    "\n",
    "# print out toy features based upon counting heuristic \n",
    "for feature in range(len(toy_h_values)):\n",
    "    feature_name = toy_h_values[feature][0]\n",
    "    heuristic_v = toy_h_values[feature][1]\n",
    "    decimal_h = round(heuristic_v / len(y_toydata), 3)\n",
    "    print(str(feature_name) + \": \" + str(heuristic_v) + \"/\" + str(len(y_toydata)) + \" (\" + str(decimal_h) + \")\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_male: 0.311\n",
      "likes_superheroes: 0.189\n"
     ]
    }
   ],
   "source": [
    "def compute_info_heuristic(x_data, y_data, outcomes, empty_h_values):\n",
    "    ''' Computes the information gain values for each feature of x_data\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    x_data : 2D list of binary values\n",
    "        Each element in x_data represents a list of each data points features\n",
    "        Each feature is either a 1 or 0\n",
    "    y_data : 1D list of integers\n",
    "        Each element in y_data is an integer representing a particular classification\n",
    "    outcomes : integer value\n",
    "        Represents the number of possible classification outcomes\n",
    "    empty_h_values : list of tuples\n",
    "        Each tuple contains a feature name and its initial information gain value (0)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    info_gains: list of tuples\n",
    "        Each tuple contains a feature name and its computed information gain value (0)\n",
    "    '''\n",
    "    \n",
    "    # intialize information gains and total data\n",
    "    info_gains = empty_h_values\n",
    "    total_data = len(y_data)\n",
    "\n",
    "    # for each attribute\n",
    "    for feature in range(len(info_gains)):\n",
    "\n",
    "        # initialize variables for y_data\n",
    "        results = [0] * outcomes\n",
    "        frac_outcomes = [0] * outcomes\n",
    "        \n",
    "        # initialize positive features subset and data corresponding to them\n",
    "        true_feat = 0\n",
    "        true_outcomes = [0] * outcomes\n",
    "        true_frac = [0] * outcomes\n",
    "        \n",
    "        # initialize false features subset and data corresponding to them\n",
    "        false_feat = 0\n",
    "        false_outcomes = [0] * outcomes\n",
    "        false_frac = [0] * outcomes\n",
    "\n",
    "        # count each classification and store in results\n",
    "        for i in range(total_data):\n",
    "            results[int(y_data[i])] += 1\n",
    "    \n",
    "        # find fraction of each classifion over total data\n",
    "        for i in range(len(results)):\n",
    "            frac_outcomes[i] = results[i] / total_data\n",
    "        \n",
    "        # calculate h_example\n",
    "        h_example = 0\n",
    "        for i in range(len(frac_outcomes)):\n",
    "            h_example += (frac_outcomes[i] * math.log(frac_outcomes[i], 2))\n",
    "        \n",
    "        h_example *= -1\n",
    "\n",
    "        # count each subset according to possible values of that attribute\n",
    "        # keep track of number of classifications for each subset\n",
    "        for i in range(total_data):\n",
    "            if x_data[i][feature] == 1:\n",
    "                true_feat += 1\n",
    "                true_outcomes[int(y_data[i])] += 1\n",
    "            else:\n",
    "                false_feat += 1\n",
    "                false_outcomes[int(y_data[i])] += 1\n",
    "        \n",
    "        # find fraction of each classifion over total data \n",
    "        for i in range(len(true_outcomes)):\n",
    "            true_frac[i] = true_outcomes[i] / true_feat\n",
    "            false_frac[i] = false_outcomes[i] / false_feat\n",
    "        \n",
    "        # initialize variables for r_cost\n",
    "        r_cost = 0\n",
    "        true_h_ex = 0\n",
    "        false_h_ex = 0\n",
    "        \n",
    "        # Solve for r_cost\n",
    "        if(0 not in true_frac):\n",
    "            for i in range(len(true_outcomes)):\n",
    "                true_h_ex += (true_frac[i] * math.log(true_frac[i], 2))\n",
    "        \n",
    "        true_h_ex *= -1\n",
    "\n",
    "        if(0 not in false_frac):\n",
    "            for i in range(len(false_outcomes)):\n",
    "                false_h_ex += (false_frac[i] * math.log(false_frac[i], 2))\n",
    "        \n",
    "        false_h_ex *= -1\n",
    "\n",
    "        r_cost = (true_h_ex * (true_feat / total_data)) + (false_h_ex * (false_feat / total_data))\n",
    "\n",
    "        # solve for information gain, set to info_gains\n",
    "        gain = round(h_example - r_cost, 3)\n",
    "        info_gains[feature] = tuple([info_gains[feature][0], gain])\n",
    "        \n",
    "    # sort by information gain, descending order\n",
    "    info_gains.sort(key=lambda a: a[1])\n",
    "    info_gains.reverse()\n",
    "    return info_gains\n",
    "\n",
    "\n",
    "# compute information gain for toy data\n",
    "toy_info_gains = compute_info_heuristic(x_toydata, y_toydata, 2, [('is_male', 0.0), ('likes_superheroes', 0.0)])\n",
    "\n",
    "# print out toy features based upon information gain\n",
    "for feature in range(len(toy_info_gains)):\n",
    "    print(str(toy_info_gains[feature][0]) + \": \" + str(toy_info_gains[feature][1]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discussion of results.\n",
    "\n",
    "Based on the results from part one, we can determine a few things when building a decision tree for these heuristics. \n",
    "\n",
    "First, we determined the counting heuristic values for each feature of the toy data. The counting heuristic value for both features was 3/4. This means that when we broke up the data set by each feature, then classified every data point by the majority classification of that subset, it was consistent with the ouput data 75% of the time. Thus, the counting heuristic doesn't tell us which feature we should start building the tree with from the root. In general, the counting heuristic isn't the best measure to determine important attributes for building decision trees. This method is helpful for determining the next attribute (good short-term), but it is a greedy algorithm that won't always get you the most efficient/smalled decision tree (bad long-term).\n",
    "\n",
    "Second, we determined the information gain values for each feature of the toy data. The information gain value for is_male is 0.311, and the value for likes_superheroes is 0.189. In information theory, if we do not know whether an event has happenned or not, then learning facts is a gain in information. Intuitively, a good attribute choice when building a tree is one that gives us the most information about how output decisions are determined. This means that is_male is giving us more information about how output decisions are made, and would create a better decision tree if picked first. On the other hand, likes_superheroes doesn't give us as much information. Despite it having the same counting heuristic value, its information gain demonstrates that it would be a bad first choice for the decision tree long-term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Compute both heuristics for simplified abalone data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Abalone Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple data\n",
    "sb_x_train = np.loadtxt('data_abalone/small_binary_x_train.csv', skiprows=1, delimiter=',')\n",
    "sb_x_test = np.loadtxt('data_abalone/small_binary_x_test.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "threec_y_train = np.loadtxt('data_abalone/3class_y_train.csv', skiprows=1, delimiter=',')\n",
    "threec_y_test = np.loadtxt('data_abalone/3class_y_test.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "# complex data\n",
    "x_train = np.loadtxt('data_abalone/x_train.csv', skiprows=1, delimiter=',')\n",
    "x_test = np.loadtxt('data_abalone/x_test.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "y_train = np.loadtxt('data_abalone/y_train.csv', skiprows=1, delimiter=',')\n",
    "y_test = np.loadtxt('data_abalone/y_test.csv', skiprows=1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: 2316/3176 (0.729)\n",
      "diam_mm: 2266/3176 (0.713)\n",
      "length_mm: 2230/3176 (0.702)\n",
      "is_male: 1864/3176 (0.587)\n"
     ]
    }
   ],
   "source": [
    "# initialize list of feature names and 0 intital heuristic values\n",
    "empty_h_values_abalone = [('is_male', 0.0), ('length_mm', 0.0), ('diam_mm', 0.0), ('height_mm', 0.0)]\n",
    "\n",
    "# compute counting heuristic for simple abalone data\n",
    "sab_h_values = compute_count_heuristic(sb_x_train, threec_y_train, 3, empty_h_values_abalone)\n",
    "\n",
    "# print out simple abalone features based upon counting heuristic \n",
    "for feature in range(len(sab_h_values)):\n",
    "    feature_name = sab_h_values[feature][0]\n",
    "    heuristic_v = sab_h_values[feature][1]\n",
    "    decimal_h = round(heuristic_v / len(threec_y_train), 3)\n",
    "    print(str(feature_name) + \": \" + str(heuristic_v) + \"/\" + str(len(threec_y_train)) + \" (\" + str(decimal_h) + \")\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: 0.173\n",
      "diam_mm: 0.15\n",
      "length_mm: 0.135\n",
      "is_male: 0.025\n"
     ]
    }
   ],
   "source": [
    "# initialize list of feature names and 0 intital information gain values\n",
    "empty_h_values_abalone = [('is_male', 0.0), ('length_mm', 0.0), ('diam_mm', 0.0), ('height_mm', 0.0)]\n",
    "\n",
    "# compute information gain for simple abalone data\n",
    "sab_info_gains = compute_info_heuristic(sb_x_train, threec_y_train, 3, empty_h_values_abalone)\n",
    "\n",
    "# print out simple abalone features based upon information gain\n",
    "for feature in range(len(sab_info_gains)):\n",
    "    print(str(sab_info_gains[feature][0]) + \": \" + str(sab_info_gains[feature][1]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Generate decision trees for full- and restricted-feature data\n",
    "\n",
    "#### (a) Print accuracy values and generate tree images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on simple training data: 0.733\n",
      "Accuracy on simple testing data: 0.722\n",
      "Accuracy on regular training data: 1.0\n",
      "Accuracy on regular testing data: 0.206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'regular_tree.pdf'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create/fit classifier for decision tree of simple abalone data\n",
    "simple_clf = sklearn.tree.DecisionTreeClassifier(criterion='entropy')\n",
    "simple_clf.fit(sb_x_train, threec_y_train)\n",
    "\n",
    "# calculate/print accuraccies for simple abalone data\n",
    "simple_train_score = simple_clf.score(sb_x_train, threec_y_train)\n",
    "simple_test_score = simple_clf.score(sb_x_test, threec_y_test)\n",
    "\n",
    "print(\"Accuracy on simple training data: \" + str(round(simple_train_score, 3)))\n",
    "print(\"Accuracy on simple testing data: \" + str(round(simple_test_score, 3)))\n",
    "\n",
    "# create/fit classifier for decision tree of regular abalone data\n",
    "regular_clf = sklearn.tree.DecisionTreeClassifier(criterion='entropy')\n",
    "regular_clf.fit(x_train, y_train)\n",
    "\n",
    "# calculate/print accuraccies for regular abalone data\n",
    "regular_train_score = regular_clf.score(x_train, y_train)\n",
    "regular_test_score = regular_clf.score(x_test, y_test)\n",
    "\n",
    "print(\"Accuracy on regular training data: \" + str(round(regular_train_score, 3)))\n",
    "print(\"Accuracy on regular testing data: \" + str(round(regular_test_score, 3)))\n",
    "\n",
    "# export simple data decision tree as pdf\n",
    "simp_export = sklearn.tree.export_graphviz(simple_clf, out_file=None)\n",
    "simp_tree = graphviz.Source(simp_export)\n",
    "simp_tree.render('simple_tree')\n",
    "\n",
    "# export regular data decision tree as pdf\n",
    "regular_export = sklearn.tree.export_graphviz(regular_clf, out_file=None)\n",
    "regular_tree = graphviz.Source(regular_export)\n",
    "regular_tree.render('regular_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Discuss the results seen for the two trees\n",
    "\n",
    "Based on the results from part three, we can determine a few things about the various accuracy-score values, the differences between the two trees, and their errors.\n",
    "\n",
    "The accuracy for the simple training data is 73.3%, and the accuracy for the simple testing data is around the same value, slighlty less, at 72.2%. This tells me that the decision tree for simple data has sub-par yet consistent accurracy for all data. In other words, this model demonstrates underfitting. On the other hand, the accuracy for the regular training data was 100%, but the accuracy for the testing data was only 20%. This tells me that the decision tree for the regular data is perfect for the data it was trained with, but really bad for any other data. In other words, this model demonstrates overfitting.\n",
    "\n",
    "Other than the fact that they are both binary trees (features are binary), the two trees differ greatly. The simple tree is relatively small, has a height of 4, is balanced, and has 16 leaves. The regular tree is very wide, has a height of at least 16, is far from a perfectly balanced tree, and has tons of leaves at various depth.\n",
    "\n",
    "Looking at the leaves of the simple data decision tree, you can see the misclassifications in the value lists of each leaf. It appears that abalones with 2 rings (large) were misclassified as 1 ring abalones (medium), and even 0 ring ones (small). It also seems like lots of 0 ring abalones were misclassified as 1 ring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
